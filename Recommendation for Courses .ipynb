{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f51de13",
   "metadata": {},
   "source": [
    "# Creating a course recommendation algorithm based similarities in course title."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7518e9",
   "metadata": {},
   "source": [
    "### This was used on an actual dataset, which will not be shown thus for the sake of future purposes you can just supliment your own here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f799a",
   "metadata": {},
   "source": [
    "### Using the EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e4fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to install package we will use for cleaning up the text we have. \n",
    "\n",
    "pip install neattext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fd6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Packages that we need.\n",
    "\n",
    "import pandas as pd\n",
    "import neattext.functions as nfx\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity,linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset. \n",
    "\n",
    "test_data = pd.read_csv('test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d253dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Examine the data. \n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ec504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let us look at the dataset to see what type of structure we are dealing with here. \n",
    "\n",
    "test_data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3711b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at how many null values are present within the 1554 rows of data we get. \n",
    "\n",
    "a = test_data.isnull().sum()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90d5d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let us Pre-process the column of interest. \n",
    "\n",
    "test_data['clean_title'] = test_data['title'].apply(nfx.remove_stopwords)\n",
    "\n",
    "test_data['clean_title'] = test_data['clean_title'].apply(nfx.remove_special_characters)\n",
    "\n",
    "test_data['clean_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4408889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize our Text.\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "cv_mat = count_vect.fit_transform(test_data['clean_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988665a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We Will convert the sparse matrix into a dense matrix. \n",
    "\n",
    "# Sparse\n",
    "cv_mat\n",
    "\n",
    "# Dense\n",
    "cv_mat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d789a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the features from the matrix \n",
    "\n",
    "df_cv_words = pd.DataFrame(cv_mat.todense(),columns=count_vect.get_feature_names())\n",
    "\n",
    "# Create a cosine similairty matrix which will be used to determine how similar one title is to the rest. \n",
    "\n",
    "cosine_sim_mat = cosine_similarity(cv_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to get the course ID/Index and at the same time drop duplicate entries. \n",
    "\n",
    "course_indices = pd.Series(test_data.index,index=test_data['title']).drop_duplicates()\n",
    "\n",
    "# Let us look at them. \n",
    "\n",
    "course_indices\n",
    "\n",
    "\n",
    "# Try to Find the index for the following course. \n",
    "\n",
    "idx = course_indices['Enter a Course here']\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e353ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compare this course with the rest of them to see which one it is most similar too. \n",
    "\n",
    "scores = list(enumerate(cosine_sim_mat[idx]))\n",
    "\n",
    "# Let us Sort the scores now. \n",
    "\n",
    "sorted_scores = sorted(scores,key=lambda x:x[1],reverse=True)\n",
    "\n",
    "# Omit the First Value/itself\n",
    "sorted_scores[1:]\n",
    "\n",
    "# Selected Courses Indices\n",
    "\n",
    "selected_course_indices = [i[0] for i in sorted_scores[1:]]\n",
    "\n",
    "# Selected Courses Scores\n",
    "\n",
    "selected_course_scores = [i[1] for i in sorted_scores[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce259464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we get the recommeneded result. \n",
    "\n",
    "recommended_result = test_data['title'].iloc[selected_course_indices]\n",
    "\n",
    "\n",
    "# Create a dataframe with the results. \n",
    "\n",
    "rec_df = pd.DataFrame(recommended_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49eaf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a function which does takes in the title and gives you the top 10 recommendations.  \n",
    "\n",
    "def recommend_course(title,num_of_rec=10):\n",
    "    # ID for title\n",
    "    idx = course_indices[title]\n",
    "    # Course Indice\n",
    "    # Search inside cosine_sim_mat\n",
    "    scores = list(enumerate(cosine_sim_mat[idx]))\n",
    "    # Scores\n",
    "    # Sort Scores\n",
    "    sorted_scores = sorted(scores,key=lambda x:x[1],reverse=True)\n",
    "    # Recomm\n",
    "    selected_course_indices = [i[0] for i in sorted_scores[1:]]\n",
    "    selected_course_scores = [i[1] for i in sorted_scores[1:]]\n",
    "    result = test_data['title'].iloc[selected_course_indices]\n",
    "    rec_df = pd.DataFrame(result)\n",
    "    rec_df['similarity_scores'] = selected_course_scores\n",
    "    return rec_df.head(num_of_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a2e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us now apply it to some random courses and see what comes ups. \n",
    "recommend_course('Enter it Here',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b46489",
   "metadata": {},
   "source": [
    "#  Using SQL Connection now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5fa3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DB connection details\n",
    "cnxn_str = (\n",
    "            \"Driver={SQL Server};\"\n",
    "            \"Server=Your Connection;\"\n",
    "            \"Database=Database HERE;\"\n",
    "            \"UID=USER ID HERE;\" \n",
    "            \"PWD=PASSWORD HERE;\"\n",
    "            \"Encrypt=True;\"\n",
    "            \"TrustServerCertificate=False;\"\n",
    "            \"Connection Timeout=60\")\n",
    "\n",
    "cnxn = pyodbc.connect(cnxn_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45044b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you just put in the SQL statement that you want to feed through.\n",
    "\n",
    "test_data_1 = pd.read_sql(\"Select col From table\", cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34855bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset.\n",
    "\n",
    "test_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0602c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = test_data_1.isnull().sum()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us Pre-process the column of interest. \n",
    "\n",
    "test_data_1['clean_title'] = test_data_1['title'].apply(nfx.remove_stopwords)\n",
    "\n",
    "test_data_1['clean_title'] = test_data_1['clean_title'].apply(nfx.remove_special_characters)\n",
    "\n",
    "test_data_1['clean_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b41ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize our Text.\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "cv_mat = count_vect.fit_transform(test_data_1['clean_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deae1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We Will convert the sparse matrix into a dense matrix. \n",
    "\n",
    "# Sparse\n",
    "cv_mat\n",
    "\n",
    "# Dense\n",
    "cv_mat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2eeb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the features from the matrix \n",
    "\n",
    "df_cv_words = pd.DataFrame(cv_mat.todense(),columns=count_vect.get_feature_names())\n",
    "\n",
    "# Create a cosine similairty matrix which will be used to determine how similar one title is to the rest. \n",
    "\n",
    "cosine_sim_mat = cosine_similarity(cv_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05231c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to get the course ID/Index and at the same time drop duplicate entries. \n",
    "\n",
    "course_indices = pd.Series(test_data_1.index,index=test_data_1['title']).drop_duplicates()\n",
    "\n",
    "# Let us look at them. \n",
    "\n",
    "course_indices\n",
    "\n",
    "# Try to Find the index for the following course. \n",
    "\n",
    "idx = course_indices['TITLE FOR COURSE']\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23de763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compare this course with the rest of them to see which one it is most similar too. \n",
    "\n",
    "scores = list(enumerate(cosine_sim_mat[idx]))\n",
    "\n",
    "# Let us Sort the scores now. \n",
    "\n",
    "sorted_scores = sorted(scores,key=lambda x:x[1],reverse=True)\n",
    "\n",
    "# Omit the First Value/itself\n",
    "sorted_scores[1:]\n",
    "\n",
    "# Selected Courses Indices\n",
    "\n",
    "selected_course_indices = [i[0] for i in sorted_scores[1:]]\n",
    "\n",
    "# Selected Courses Scores\n",
    "\n",
    "selected_course_scores = [i[1] for i in sorted_scores[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we get the recommeneded result. \n",
    "\n",
    "recommended_result = test_data_1['title'].iloc[selected_course_indices]\n",
    "\n",
    "\n",
    "# Create a dataframe with the results. \n",
    "\n",
    "rec_df = pd.DataFrame(recommended_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598046ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a function which does takes in the title and gives you the top 10 recommendations.  \n",
    "\n",
    "def recommend_course(title,num_of_rec=10):\n",
    "    # ID for title\n",
    "    idx = course_indices[title]\n",
    "    # Course Indice\n",
    "    # Search inside cosine_sim_mat\n",
    "    scores = list(enumerate(cosine_sim_mat[idx]))\n",
    "    # Scores\n",
    "    # Sort Scores\n",
    "    sorted_scores = sorted(scores,key=lambda x:x[1],reverse=True)\n",
    "    # Recomm\n",
    "    selected_course_indices = [i[0] for i in sorted_scores[1:]]\n",
    "    selected_course_scores = [i[1] for i in sorted_scores[1:]]\n",
    "    result = test_data_1['title'].iloc[selected_course_indices]\n",
    "    rec_df = pd.DataFrame(result)\n",
    "    rec_df['similarity_scores'] = selected_course_scores\n",
    "    return rec_df.head(num_of_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us now apply it to some random courses and see what comes ups. \n",
    "recommend_course('Appliance Industry Overview',3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e835a7c4",
   "metadata": {},
   "source": [
    "# Using SQL on Courses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f92ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you just put in the SQL statement that you want to feed through.\n",
    "\n",
    "test_data_2 = pd.read_sql(\"Select col From table\", cnxn)\n",
    "\n",
    "test_data_2\n",
    "\n",
    "a = test_data_2.isnull().sum()\n",
    "a\n",
    "\n",
    "# Let us Pre-process the column of interest. \n",
    "\n",
    "test_data_2['clean_title'] = test_data_2['title'].apply(nfx.remove_stopwords)\n",
    "\n",
    "test_data_2['clean_title'] = test_data_2['clean_title'].apply(nfx.remove_special_characters)\n",
    "\n",
    "test_data_2['clean_title']\n",
    "\n",
    "# Vectorize our Text.\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "cv_mat = count_vect.fit_transform(test_data_2['clean_title'])\n",
    "\n",
    "# We Will convert the sparse matrix into a dense matrix. \n",
    "\n",
    "# Sparse\n",
    "cv_mat\n",
    "\n",
    "# Dense\n",
    "cv_mat.todense()\n",
    "\n",
    "# Grab the features from the matrix \n",
    "\n",
    "df_cv_words = pd.DataFrame(cv_mat.todense(),columns=count_vect.get_feature_names())\n",
    "\n",
    "# Create a cosine similairty matrix which will be used to determine how similar one title is to the rest. \n",
    "\n",
    "cosine_sim_mat = cosine_similarity(cv_mat)\n",
    "\n",
    "# We want to get the course ID/Index and at the same time drop duplicate entries. \n",
    "\n",
    "course_indices = pd.Series(test_data_2.index,index=test_data_2['title']).drop_duplicates()\n",
    "\n",
    "# Let us look at them. \n",
    "\n",
    "course_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to Find the index for the following course. \n",
    "\n",
    "idx = course_indices['COURSE TITLE HERE']\n",
    "idx\n",
    "\n",
    "# Let us compare this course with the rest of them to see which one it is most similar too. \n",
    "\n",
    "scores = list(enumerate(cosine_sim_mat[idx]))\n",
    "\n",
    "# Let us Sort the scores now. \n",
    "\n",
    "sorted_scores = sorted(scores,key=lambda x:x[1],reverse=True)\n",
    "\n",
    "# Omit the First Value/itself\n",
    "sorted_scores[1:]\n",
    "\n",
    "# Selected Courses Indices\n",
    "\n",
    "selected_course_indices = [i[0] for i in sorted_scores[1:]]\n",
    "\n",
    "# Selected Courses Scores\n",
    "\n",
    "selected_course_scores = [i[1] for i in sorted_scores[1:]]\n",
    "\n",
    "# Now we get the recommeneded result. \n",
    "\n",
    "recommended_result = test_data_2['title'].iloc[selected_course_indices]\n",
    "\n",
    "\n",
    "# Create a dataframe with the results. \n",
    "\n",
    "rec_df = pd.DataFrame(recommended_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d280117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a function which does takes in the title and gives you the top 10 recommendations.  \n",
    "\n",
    "def recommend_course(title,num_of_rec=10):\n",
    "    # ID for title\n",
    "    idx = course_indices[title]\n",
    "    # Course Indice\n",
    "    # Search inside cosine_sim_mat\n",
    "    scores = list(enumerate(cosine_sim_mat[idx]))\n",
    "    # Scores\n",
    "    # Sort Scores\n",
    "    sorted_scores = sorted(scores,key=lambda x:x[1],reverse=True)\n",
    "    # Recomm\n",
    "    selected_course_indices = [i[0] for i in sorted_scores[1:]]\n",
    "    selected_course_scores = [i[1] for i in sorted_scores[1:]]\n",
    "    result = test_data_2['title'].iloc[selected_course_indices]\n",
    "    rec_df = pd.DataFrame(result)\n",
    "    rec_df['similarity_scores'] = selected_course_scores\n",
    "    return rec_df.head(num_of_rec)\n",
    "\n",
    "# Let us now apply it to some random courses and see what comes ups. \n",
    "recommend_course('Training Course TITLE HERE',3)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
